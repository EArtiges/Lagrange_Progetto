{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import json\n",
    "import time\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import twython\n",
    "from twython import TwythonRateLimitError\n",
    "import Twitter_scraping as scraper\n",
    "import string\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from requests.packages.urllib3.exceptions import ReadTimeoutError\n",
    "import logging\n",
    "logging.basicConfig(filename='Twitter.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid\n"
     ]
    }
   ],
   "source": [
    "APP_KEY = 'ZIvxV0lZJnQI2FOuEqi0zzQqU'\n",
    "APP_SECRET = '28z7HZuCNX71NMc5TO8ga3woravEt5wFsvm7Z2Q7LERBpoSCno'\n",
    "twitter = twython.Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "twitter = twython.Twython(APP_KEY, access_token=ACCESS_TOKEN)\n",
    "\n",
    "print('Grid')\n",
    "# Define the grid we want to work with.\n",
    "Grid=pkl.load(open('../Results/2019-02-05_8_5000_diy_word2vec/pickle/Grid.pkl', 'rb'))\n",
    "latitudes=set([g[0] for g in Grid])\n",
    "longitudes=set([g[1] for g in Grid])\n",
    "Grid=[]\n",
    "for lat in sorted(latitudes):\n",
    "    for lon in sorted(longitudes):\n",
    "        Grid.append((lat,lon))\n",
    "grid_str=[str(g[0])+','+str(g[1])+',0.25km' for g in Grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.576453909502152,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.582826032218302,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.589198154934451,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.595570277650601,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.601942400366751,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.608314523082901,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.6146866457990505,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.6210587685152005,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.62743089123135,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.6338030139475,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.6401751366636494,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.646547259379799,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.652919382095949,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.659291504812099,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.665663627528249,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.672035750244399,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.678407872960549,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.684779995676698,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.691152118392848,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.697524241108998,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.703896363825148,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.710268486541298,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.716640609257448,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.723012731973598,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.729384854689748,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.735756977405897,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.742129100122047,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.748501222838197,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.754873345554347,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.761245468270497,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00449999999999,7.767617590986647,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.576453909502152,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.582826032218302,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.589198154934451,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.595570277650601,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.601942400366751,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.608314523082901,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.6146866457990505,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.6210587685152005,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.62743089123135,0.25km'}\n",
      "0 tweets collected.\n",
      "Starting to query tweets\n",
      "Searching with parameters:  {'q': 'torino', 'count': 70, 'max_id': None, 'geocode': '45.00899999999999,7.6338030139475,0.25km'}\n"
     ]
    }
   ],
   "source": [
    "print('queries')\n",
    "# Run the queries we want on the grid we choose\n",
    "statuses_all=[]\n",
    "user_loc_dict={}\n",
    "for query in ['torino','san salvario','nizza']: #,'porta nuova','piazza castello','mole','vanchiglia','vanchiglietta','lingotto','san donato','borgo crimea','bordo po','santa rita','mirafiori','crocetta','cenisia']:\n",
    "    statuses=[]\n",
    "    for g in grid_str:\n",
    "        last_id=None\n",
    "        try:\n",
    "            search_parameters = dict(q=query , count = 70, max_id = last_id, geocode=g)\n",
    "        except (ReadTimeoutError, ConnectionError, ConnectionResetError, TwythonRateLimitError,OSError) as exc:\n",
    "            logging.exception(\"message\")\n",
    "            continue\n",
    "        print(\"Starting to query tweets\")\n",
    "        statuses+=scraper.query_by_word(search_parameters, twitter)\n",
    "    statuses_all+=statuses\n",
    "    print('filtering')\n",
    "    # For all the tweets we got, keep only the interesting info\n",
    "    tweets=[]\n",
    "    for status in statuses:\n",
    "        rt = 'retweeted_status' in status\n",
    "        text = status['retweeted_status']['text'] if rt else status['text']\n",
    "        status['geo'] = status['retweeted_status']['geo'] if rt else status['geo']\n",
    "        try:\n",
    "            loc=status['geo']['coordinates'] if status['geo'] else status['query_loc']\n",
    "            loc=','.join([str(i) for i in [loc]])\n",
    "        except KeyError:\n",
    "            loc=status['query_loc']\n",
    "        tweets.append((np.uint64(status['id_str']),\n",
    "                       text,\n",
    "                       rt,\n",
    "                       status['created_at'],\n",
    "                       status['lang'],loc,\n",
    "                       np.uint64(status['user']['id_str'])))\n",
    "\n",
    "    print('making/pickling dataframe')\n",
    "    # Store everything in a dataset and pickle it\n",
    "    df = pd.DataFrame(tweets,\n",
    "                  columns=['status_id', 'text', 'rt', 'created_at', 'lang', 'location','user_id',])\n",
    "    df = df.set_index('status_id')\n",
    "    df.created_at = pd.to_datetime(df.created_at)\n",
    "    df.to_pickle('DF/dataframe_query_{}.pkl'.format(query))\n",
    "    \n",
    "    print('list of users')\n",
    "    #Make a list of users and build their spatial profiles\n",
    "    user_loc=[e for e in zip(df.user_id.tolist(), df.location.tolist())]\n",
    "    for e in user_loc:\n",
    "        if not e[0] in user_loc_dict:\n",
    "            user_loc_dict[e[0]]=[e[1]]\n",
    "        else: \n",
    "            user_loc_dict[e[0]].append(e[1])\n",
    "    for e in user_loc_dict:\n",
    "        user_loc_dict[e]=scraper.spatial_profile(user_loc_dict[e])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pickling dictionary')\n",
    "# Save the dicionary of users spatial profiles\n",
    "pkl.dump(user_loc_dict, open('user_loc_dict.pkl', 'wb'))\n",
    "\n",
    "\n",
    "print(\"Query executed. Saving files in a JSON\")\n",
    "with gzip.open('torino_2019.json.gz', 'wt') as gf:\n",
    "    for status in statuses_all:\n",
    "        gf.write(json.dumps(status) + \"\\n\")\n",
    "        \n",
    "print(\"Starting to query users.\")\n",
    "# Scrape users timelines\n",
    "ID = list(user_loc_dict.keys())\n",
    "date_start = parser.parse('2000-02-01 00:00:00+00:00')\n",
    "print(len(ID), 'users to scrape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for user_ID in ID:\n",
    "    print(\"scraping user {}\".format(user_ID))\n",
    "    while(True):\n",
    "        try:\n",
    "            df=scraper.get_user_timeline(user_ID,date_start,twitter)\n",
    "            df.to_pickle('DF/USERS/dataframe_user_{}.pkl'.format(user_ID))\n",
    "        except (ReadTimeoutError, ConnectionResetError, ConnectionError,TwythonRateLimitError,OSError) as exc:\n",
    "            logging.exception(\"message\")\n",
    "            continue\n",
    "        break\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
